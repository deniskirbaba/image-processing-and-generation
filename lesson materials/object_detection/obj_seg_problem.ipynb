{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](\\imgs\\cv_tsksk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача:\n",
    "найти границы объектов на изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](\\imgs\\label_test.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'dog',\n",
       " 'points': [[22.762376237623762, 57.68316831683168],\n",
       "  [164.84158415841583, 295.8019801980198]],\n",
       " 'group_id': None,\n",
       " 'shape_type': 'rectangle',\n",
       " 'flags': {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path = 'imgs\\\\test.json'\n",
    "with open(json_path, \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "data['shapes'][0] # top left bottom right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Как представить выход сети?\n",
    "2. Какие лоссы использовать?\n",
    "3. Как мерить качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-CNN\n",
    "\n",
    "1. Определение набора гипотез.\n",
    "2. Извлечение из предполагаемых регионов признаков с помощью сверточной нейронной сети и их кодирование в вектор.\n",
    "3. Классификация объекта внутри гипотезы на основе вектора из шага 2.\n",
    "4. Улучшение (корректировка) координат гипотезы.\n",
    "5. Все повторяется, начиная с шага 2, пока не будут обработаны все гипотезы с шага 1.\n",
    "\n",
    "![title](\\imgs\\rcnn.jpg)\n",
    "\n",
    "1. Отбор гипотез: генерируем из исходного изображения набор его частей (как мозайку). Для более осознаного выделения (чтобы в нарезанных частях были объекты) можно использовать Selective Search – верхнеуровнево, он позволяет составить набор гипотез (класс объекта пока не имеет значения), на основе сегментации определить границы объектов по интенсивности пикселей, перепаду цветов, контраста и текстур. Для более точной последующей обработки каждая гипотеза дополнительно расширяется на 16 пикселей во всех 4 направлениях – как бы добавляя контекст.\n",
    "    \n",
    "    Итог:\n",
    "\n",
    "    Вход: исходное изображение.\n",
    "    \n",
    "    Выход: набор гипотез разного размера и соотношения сторон.\n",
    "\n",
    "2. Извлечение из предполагаемых регионов признаков с помощью сверточной нейронной сети и их кодирование в вектор.\n",
    "\n",
    "    Итог:\n",
    "\n",
    "    Вход: каждая из предложенных на предыдущем шаге гипотеза.\n",
    "    \n",
    "    Выход: векторное представление для каждой гипотезы.\n",
    "\n",
    "3. Классификация объекта внутри гипотезы на основе вектора из шага 2.\n",
    "\n",
    "    Итог:\n",
    "\n",
    "    Вход: вектор каждой из предложенных гипотез из предпоследнего слоя сети (в случае AlexNet это FC7).\n",
    "    \n",
    "    Выход: после последовательного запуска каждой гипотезы, получаем матрицу размерности $2000×N_{c}$, отображающую класс объекта для каждой гипотезы.\n",
    "\n",
    "4. Улучшение (корректировка) координат гипотезы.\n",
    "    \n",
    "    Итог:\n",
    "\n",
    "    Вход: карта признаков из последнего MaxPooling слоя для каждой гипотезы, которая содержит любой объект, кроме фона.\n",
    "    \n",
    "    Выход: поправки к координатам ограничивающей рамки гипотезы. \n",
    "\n",
    "\n",
    "В заключение выделим основные недостатки такого подхода:\n",
    "\n",
    "1. Гипотезы, предложенные на шаге 1, могут частично дублировать друг друга – разные гипотезы могут состоять из одинаковых частей, а каждая такая гипотеза отдельно обрабатывалась нейронной сетью. Так получается, что большая часть запусков сети более или менее дублирует друг друга без надобности.\n",
    "\n",
    "2. Нельзя использовать для real-time работы, поскольку на проход 1 изображения (кадра) тратится ~53 секунды (NVIDIA Titan Black GPU).\n",
    "\n",
    "3. Алгоритм выделения гипотез никак не обучается, а поэтому дальнейшее улучшение качества почти невозможно (никто не отменял плохие гипотезы).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast R-CNN\n",
    "\n",
    "Процесс обработки изображения изменился и выглядит следующим образом:\n",
    "\n",
    "1. Извлечение карты признаков изображения (не для каждой гипотезы по отдельности, а для всего изображения целиком);\n",
    "2. Поиск гипотез (аналогично R-CNN на основе Selective Search);\n",
    "3. Сопоставление каждой гипотезы с местом на карте признаков – т.е. использование единого набора выделенных признаков для каждой гипотезы (координаты гипотез можно однозначно сопоставить с местоположением на карте признаков);\n",
    "4. Классификация каждой гипотезы и исправление координат ограничивающей рамки (эту часть стало возможным запускать параллельно, поскольку больше нет зависимости от SVM-классификации).\n",
    "\n",
    "### RoI layer\n",
    "\n",
    "В изначальной концепции R-CNN каждая предложенная гипотеза по отдельности обрабатывается с помощью CNN – такой подход стал своеобразным бутылочным горлышком. Для решения этой проблемы был разработан Region of Interest (RoI) слой. Этот слой позволяет единожды обрабатывать изображение целиком с помощью нейронной сети, получая на выходе карту признаков, которая далее используется для обработки каждой гипотезы.\n",
    "\n",
    "Как подать на вход полносвязному слою гипотезы разного размера и соотношения сторон? Для этого и необходим RoI слой, который преобразовывает изображение с размерами $I_{h}×I_{w}$ в размеры $O_{h}×O_{w}$. Для этого необходимо исходное изображение разделить на сетку размером $O_{h}×O_{w}$ (размер ячейки примерно $\\frac{I_{h}}{O_{h}}×\\frac{I_{w}}{O_{w}}$) и из каждой ячейки выбрать максимальное число.\n",
    "\n",
    "![title](\\imgs\\roi.jpg)\n",
    "\n",
    "    Итог:\n",
    "\n",
    "    Вход: координаты гипотезы и карта признаков изначального изображения;\n",
    "\n",
    "    Выход: векторное представление гипотезы.\n",
    "\n",
    "### Multi-task loss\n",
    "\n",
    "В одновременном обучении сети для задач регрессии ограничивающих рамок и классификации применяется специальная лосс-функция:\n",
    "\n",
    "$L(P,u,t^{u},v)=L_{cls}(P,u)+\\lambda[u≥1]L_{loc}(t^{u},v)$\n",
    "\n",
    "\n",
    "Здесь:\n",
    "\n",
    "$\\lambda$ необходим для настройки баланса между двумя функции (авторы использовали $\\lambda$=1);\n",
    "$u$ — правильный класс;\n",
    "$L_{cls}$ представляет собой функции ошибки для классификации $L_{cls}(P,u)=-logP_{u}$;\n",
    "$L_{loc}$ является SmoothL1-функцией и измеряет разницу между $v=(v_{x},v_{y},v_{w},v_{h})$ и $t^{u}=(t^u_x,t^u_y,t^u_w,t^u_h)$ значениями:\n",
    "\n",
    "$SmoothL1=\\left \\{ \\begin{matrix} \\frac{1}{2}x^{2}, & if\\left | x \\right | <1\\\\ \\left | x \\right |-\\frac{1}{2}, & otherwise \\end{matrix}\\right.$\n",
    "\n",
    "\n",
    "Здесь, $x$ обозначает разность целевого значения и предсказания $t^u_i-v_{i}$. Такая функция сочетает в себе преимущества L1 и L2 функции, поскольку является устойчивой при больших значениях $x$ и не сильно штрафует при малых значениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN\n",
    "![title](\\imgs\\rpn.jpeg)\n",
    "\n",
    "Главная задача заменить Selective Search на что то более быстрое. Для этого был предложен\n",
    "\n",
    "### RPN\n",
    "\n",
    "![title](\\imgs\\faster.jpg)\n",
    "\n",
    "1. Получим карту признаков $c×\\frac{H}{16}×\\frac{W}{16}$ с предыдущего шага.\n",
    "2. Применим сверточный слой 3×3 (отступ равен единице – итоговая матрица не меняется в размерах). По всей видимости, этот шаг применяется авторами для дополнительного наращивания рецептивного поля ($P_{0}=106$, $r_{0}=228$).\n",
    "\n",
    "* Ячейке ($i,j$) карты признаков соответствует вектор размерности $c$ (в нашем случае 512).\n",
    "\n",
    "1. К каждому такому вектору применимы два сверточных слоя с ядром 1×1 и количеством выходных каналов $\\hat{c}$ (ядро такого размера просто отображает размерность $c$ в $\\hat{c}$):\n",
    "    * Первой слой (cls) имеет параметр $\\hat{c}=2k$ – необходим для определения вероятности наличия или отсутствия какого-либо объекта внутри гипотезы (классификация с 2 классами).\n",
    "    * Второй слой (reg) имеет параметр $\\hat{c}=4k$ – необходим для определения координат гипотез.\n",
    "\n",
    "Отметим, что полученные вектора можно переформировать в матрицы $k×2$ и $k×4$. Таким образом получаем матрицы, где $i$ строке соответствуют значения для конкретной гипотезы.\n",
    "\n",
    "Возникает вполне логичный вопрос, как из вектора, который поступает в reg слой можно определить абсолютные координаты гипотез? Ответ прост – никак. Для правильного определения координат необходимо использовать так называемые якоря (anchors) и поправки к их координатам.\n",
    "\n",
    "Якорем называют четырехугольник разного соотношения сторон (1:1, 2:1, 1:2) и размеров (128×128, 256×256, 512×512). Центром якоря считается центр ячейки ($i,j$) карты признаков. Так, например, возьмем ячейку (7,7), центром которой являются значения (7.5,7.5), что соответствует координатам (120,120) исходного изображения (16×7.5). Сопоставим с этими координатами прямоугольники трех соотношений сторон и трех размеров (всего получается 3×3=9). В будущем слой reg по отношению к этим координатам будет выдавать соответствующие правки, тем самым корректируя местоположение и форму ограничивающей рамки.\n",
    "\n",
    "    Итог:\n",
    "\n",
    "    Вход: карта признаков изначального изображения;\n",
    "    \n",
    "    Выход: гипотезы, содержащие какой-либо объект.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss функция\n",
    "\n",
    "Для обучения RPN используется следующее обозначение классов:\n",
    "\n",
    "Позитивными являются все якоря, имеющие пересечение (IoU) более 0.7 или имеющие наибольшее пересечение среди всех якорей (применяется в случае, если нет пересечения более 0.7).\n",
    "Негативными являются все якоря, имеющие пересечение менее 0.3.\n",
    "Все остальные якоря не участвуют в обучении (по сути, они являются нейтральными).\n",
    "\n",
    "Таким образом класс $p^*_i$ якоря присуждается по следующему правилу:\n",
    "\n",
    "$p^*_i = \\begin{cases} 1 & if IoU > 0.7 \\\\ 0 & if IoU < 0.3 \\\\ nothing & otherwise \\end{cases} $\n",
    "\n",
    "\n",
    "С такими обозначениями минимизируется следующая функция:\n",
    "\n",
    "$L(\\{p_i\\}, \\{t_i\\}) = \\frac{1}{N_{cls}} \\sum_i L_{cls}(p_i, p^*_i) + \\lambda \\frac{1}{N_{loc}} \\sum_i p^*_i L_{reg} (t_i, t^*_i)$\n",
    "\n",
    "\n",
    "Здесь:\n",
    "\n",
    "$i$ – номер якоря;\n",
    "$p_{i}$ – вероятность нахождения объекта в $i$ якоре;\n",
    "$p^*_i$ – правильный номер класса (обозначен выше);\n",
    "$t_{i}$ – 4 предсказанные поправки к координатам;\n",
    "$t^*_i$ – ожидаемая (ground truth) поправки к координатам;\n",
    "$L_{cls}(p_{i},p^*_i)$ – бинарный log-loss;\n",
    "$L_{reg}(t_{i},t^*_i)$ – SmoothL1 лосс. Активируется только в случае $p^*_i=1$, т.е. если гипотеза содержит хоть какой-нибудь объект;\n",
    "$\\begin{Bmatrix}p_{i}\\end{Bmatrix}$ и $\\begin{Bmatrix}t_{i}\\end{Bmatrix}$ – выходы классификационной и регрессионной модели соответственно;\n",
    "$\\lambda$ – коэффициент для настройки баланса между классификацией и регрессией.\n",
    "\n",
    "Обе части комбинированного лосса нормализуются на $N_{cls}$ и $N_{loc}$ соответственно. Авторы использовали $N_{cls}$ равный размеру мини-батча (256), а $N_{loc}$ равный количеству якорей.\n",
    "\n",
    "Для регрессии поправок к ограничивающим рамкам значения инициализируются и подсчитываются следующим образом:\n",
    "\n",
    "$t_x = \\frac{(x - x_a)}{w_a}, \\quad\\quad t^*_x = \\frac{(x^*-x_a)}{w*} \\\\ t_y = \\frac{(y - y_a)}{h_a}, \\quad\\quad t^*_y = \\frac{(y^* - y_a)}{h_a} \\\\ t_w = \\log{\\frac{w}{w_a}}, \\quad\\quad t^*_w = \\log{\\frac{w^*}{w_a}} \\\\ t_h = \\log{\\frac{h}{h_a}}, \\quad\\quad t^*_h = \\log{\\frac{h^*}{h_a}}$\n",
    "\n",
    "\n",
    "Здесь $x$, $y$, $w$ и $h$ обозначают центр, ширину и высоту ограничивающей рамки. Переменные $x$, $x^{*}$ и $x_{a}$ обозначают предсказание, ground truth и значение якорей (для $y$, $w$ и $h$ аналогично).\n",
    "\n",
    "Обучение на полном списке якорей будет иметь смещение в сторону отрицательного класса (гипотез с таким классом в разы больше). В связи с этим мини-батч формируется в соотношении 1:1 позитивных якорей к негативным. В случае, если не удается найти соответствующее количество позитивных якорей, мини-батч дозаполняется с помощью негативных классов.\n",
    "\n",
    "### Общее обучение сети\n",
    "\n",
    "Основной задачей является совместное использование весов между двумя модулями –это повысит скорость работы. Поскольку невозможно (или довольно-таки сложно) обучить сразу два независимых модуля, авторы статьи используют итеративный подход:\n",
    "\n",
    "1. Тренировка RPN сети. Сверточные слои инициализируются весами, ранее полученными при тренировке на ImageNet. Дообучаем на задаче определения регионов с каким-либо классом (уточнение класса занимается часть Fast R-CNN).\n",
    "2. Тренировка Fast R-CNN сети. Так же, как и в п.1 инициализируем Fast R-CNN весами, ранее полученными при обучении на ImageNet. Дообучаем, используя гипотезы об объектах с помощью RPN сети, обученной в п.1. В этот раз задачей обучения является уточнение координат и определение конкретного класса объекта.\n",
    "3. Используя веса из п.2 обучаем только RPN часть (слои, идущие до RPN сети, принадлежащие feature extractor, замораживаются и никак не изменяются).\n",
    "4. Используя веса из п.3 (то есть, уже более точно настроенный RPN), обучаем слои для Fast R-CNN (остальные веса – идущие ранее или относящиеся к RPN — заморожены).\n",
    "\n",
    "С помощью такого итеративного обучения получается, что вся сеть построена на одних и тех же весах. Можно и дальше обучать сеть по такому принципу, но авторы отмечают, что сильных изменений в метриках нет.\n",
    "\n",
    "### Процесс предсказания\n",
    "\n",
    "Во время использования нейронных сетей для предсказаний прохождение изображения выглядит так:\n",
    "\n",
    "1. Изображение поступает на вход нейронной сети, генерируя карту признаков.\n",
    "2. Каждая ячейка карты признаков обрабатывается с помощью RPN, выдавая в результате поправки к положению якорей и вероятность наличия объекта любого класса.\n",
    "3. Соответствующие предсказанные рамки далее на основе карты признаков и RoI слоя поступают в дальнейшую обработку Fast R-CNN части.\n",
    "4. На выходе получаем уже конкретный класс объектов и их точное положение на изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "344656c6016b7921ac5c2936527ce8092136786e3055fe30f9babf9114d9a927"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
